import os
import warnings
from langchain.prompts import ChatPromptTemplate
from langchain_community.llms import Ollama
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient
from langchain_community.embeddings import HuggingFaceEmbeddings

# Ocultar warnings de deprecaci√≥n
warnings.filterwarnings("ignore", category=DeprecationWarning)

# PALABRAS CLAVE M√âDICAS Y CL√çNICAS
KEYWORDS_MAP = {
    "criterios": [
        "criterios de inclusi√≥n", "criterios de exclusi√≥n", "consentimiento informado",
        "participante elegible", "diagn√≥stico", "reca√≠das", "EDSS", "selecci√≥n", "aleatorizaci√≥n",
        "poblaci√≥n de estudio", "poblaci√≥n por protocolo", "enmienda de protocolo", "FCI", "firma de consentimiento"
    ],
    "farmacocinetica": [
        "PK", "farmacocin√©tica", "farmacodinamia", "Cmax", "Tmax", "AUC",
        "vida media", "clearance", "concentraci√≥n plasm√°tica", "dosis", "curva PK", 
        "muestras de sangre", "absorci√≥n", "distribuci√≥n", "metabolismo", "eliminaci√≥n"
    ],
    "biomarcadores": [
        "biomarcador", "biomarcadores", "NfL", "cadena ligera de neurofilamentos",
        "expresi√≥n g√©nica", "gen√≥mica", "prote√≥mica", "biolog√≠a molecular", "respuestas inmunes", 
        "marcadores inflamatorios", "panel de biomarcadores", "an√°lisis de biomarcadores"
    ],
    "seguridad": [
        "eventos adversos", "EA", "eventos serios", "efectos secundarios", "farmacovigilancia",
        "seguimiento de seguridad", "desenlace", "complicaciones", "reacciones adversas",
        "mortalidad", "interrupci√≥n del tratamiento", "notificaci√≥n de eventos"
    ],
    "procedimientos": [
        "visitas de seguimiento", "procedimiento", "examen f√≠sico", "ECG", "laboratorio cl√≠nico",
        "pruebas de embarazo", "evaluaciones", "subestudio", "toma de muestras", "monitoreo"
    ],
    "estadistica": [
        "an√°lisis estad√≠stico", "modelo NB", "regresi√≥n", "intervalo de confianza",
        "cociente de tasas", "mediana", "an√°lisis de sensibilidad", "endpoint",
        "criterio de valoraci√≥n", "p-valor", "power", "desviaci√≥n est√°ndar"
    ],
    "estructuras": [
        "tabla", "figura", "cuadro", "anexo", "ap√©ndice", "tabla PK", "tabla de biomarcadores",
        "tabla de eventos adversos", "tabla de criterios", "tabla de an√°lisis"
    ],
    "regulaciones": [
        "IRB", "IEC", "GCP", "ICH", "regulaci√≥n europea", "consentimiento √©tico",
        "comit√© √©tico", "autorizaci√≥n", "aprobaci√≥n regulatoria"
    ]
}

# PALABRAS CLAVE M√âDICAS GLOBALES (aplicables a cualquier estudio cl√≠nico)
KEYWORDS_MEDICAS = [
    "pk", "farmacocin√©tica", "cmax", "tmax", "auc", "t1/2", "clearance",
    "exposici√≥n", "concentraci√≥n plasm√°tica", "niveles plasm√°ticos", "par√°metros pk",
    "biomarcador", "biomarcadores", "nfl", "expresi√≥n g√©nica", "prote√≠nas",
    "niveles s√©ricos", "respuesta biol√≥gica", "marcadores de laboratorio",
    "evaluaciones", "visitas", "cronograma", "tabla de evaluaciones",
    "par√°metros medidos", "puntos temporales", "semana", "d√≠a", "muestreo",
    "procedimientos", "asignaciones", "recolecion de muestras",
    "eventos adversos", "seguridad", "efectos adversos", "acontecimientos adversos",
    "serious adverse event", "seguimiento", "monitorizaci√≥n",
    "eficacia", "objetivos secundarios", "objetivos primarios",
    "resultados cl√≠nicos", "endpoints", "an√°lisis estad√≠stico", "poblaci√≥n de an√°lisis"
]

PROMPT_TEMPLATE = """
Eres un especialista en an√°lisis de documentos cl√≠nicos. Tu tarea es EXTRAER INFORMACI√ìN PRECISA bas√°ndote √öNICAMENTE en el contexto proporcionado.

CONTEXTO:
{context}

PREGUNTA: {question}

INSTRUCCIONES CR√çTICAS - DEBES SEGUIR ESTAS REGLAS:

**EXTRACCI√ìN OBLIGATORIA:**
1. SI encuentras la informaci√≥n solicitada: EXTRAE y LISTA todos los elementos espec√≠ficos
2. SI NO encuentras la informaci√≥n: Di claramente "No encontr√© [informaci√≥n solicitada] en el documento"
3. NO inventes, NO supongas, NO uses conocimiento externo

**PARA CRITERIOS/LISTAS/TABLAS:**
4. Si es una lista: Extrae TODOS los elementos, no solo algunos
5. Si es una tabla: Revisa TODAS las filas y columnas relevantes
6. Incluye n√∫meros de p√°gina cuando est√©n disponibles

**B√öSQUEDA EXHAUSTIVA:**
7. Revisa TODO el contexto proporcionado antes de responder
8. Si hay informaci√≥n en m√∫ltiples secciones: CONSOLIDA y muestra TODOS los datos
9. Si hay discrepancias: Menciona todas las versiones encontradas

**PROHIBIDO:**
- "No hay informaci√≥n disponible en esta secci√≥n" (es redundante)
- "Revis√© pero no encontr√©" (di directamente si encontraste o no)
- Dar ejemplos hipot√©ticos
- Usar lenguaje vago como "algunos", "varios", "entre otros"

**FORMATO DE RESPUESTA OBLIGATORIO:**
- Si ENCONTRASTE informaci√≥n: 
  "ENCONTR√â [n√∫mero] elementos:"
  [Lista numerada completa]
  "Fuente: [p√°ginas/tablas donde se encontr√≥]"

- Si NO ENCONTRASTE informaci√≥n:
  "No encontr√© [informaci√≥n espec√≠fica] en el documento revisado."

Respuesta en espa√±ol:
"""

# Configuraci√≥n de Qdrant LOCAL
QDRANT_URL = "http://localhost:6333"
QDRANT_API_KEY = ""
COLLECTION_NAME = "rag_documents"

def get_unified_llm():
    return Ollama(
        model="llama3.2:3b",
        temperature=0.1,
        top_p=0.7,
        num_predict=1200,
        timeout=600,
        top_k=40,
        repeat_penalty=1.1
    )

def get_embedding_function():
    os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    os.environ["CUDA_VISIBLE_DEVICES"] = ""

    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={
            'device': 'cpu',
            'trust_remote_code': True
        },
        encode_kwargs={
            'normalize_embeddings': True,
            'batch_size': 32
        }
    )

def query_rag(query_text: str):
    try:
        # Conectar a Qdrant
        client = QdrantClient(
            url=QDRANT_URL,
            api_key=QDRANT_API_KEY,
        )
        
        # Verificar que la colecci√≥n existe
        collections = client.get_collections()
        collection_exists = any(col.name == COLLECTION_NAME for col in collections.collections)
        
        if not collection_exists:
            print("Error: La colecci√≥n no existe. Ejecuta primero: python populate_database.py")
            return "Error: Base de datos no encontrada"
        
        # Obtener informaci√≥n de la colecci√≥n
        collection_info = client.get_collection(COLLECTION_NAME)
        document_count = collection_info.points_count
        print(f"Documentos en la base de datos: {document_count}")
        
        if document_count == 0:
            print("La base de datos est√° vac√≠a. Ejecuta: python populate_database.py")
            return "Error: Base de datos vac√≠a"

        # Crear vector store
        embedding_function = get_embedding_function()
        vector_store = QdrantVectorStore(
            client=client,
            collection_name=COLLECTION_NAME,
            embedding=embedding_function,
        )

        # B√öSQUEDA INTELIGENTE: M√°s resultados con umbral bajo
        results = vector_store.similarity_search_with_relevance_scores(query_text, k=80)
        
        if not results:
            print("No se encontraron resultados relevantes")
            return "No se encontraron documentos relevantes"
        
        # DETECCI√ìN DE PALABRAS CLAVE: Identificar contexto m√©dico
        user_query_lower = query_text.lower()
        matched_keywords = []
        detected_categories = []
        
        for category, keywords in KEYWORDS_MAP.items():
            for keyword in keywords:
                if keyword in user_query_lower:
                    matched_keywords.append(keyword)
                    if category not in detected_categories:
                        detected_categories.append(category)
        
        if matched_keywords:
            print(f"Palabras clave detectadas ({len(set(matched_keywords))}): {', '.join(set(matched_keywords)[:5])}...")
        
        # FILTRADO INTELIGENTE CON BOOST: Mantener resultados relevantes
        filtered_results = []
        for doc, score in results:
            boost = 0
            if matched_keywords and any(word in doc.page_content.lower() for word in matched_keywords):
                boost = 0.15
            
            final_score = score + boost
            
            if final_score > 0.15:
                filtered_results.append(doc)
        
        if not filtered_results:
            filtered_results = [doc for doc, _ in results[:50]]
        
        print(f"‚úÖ Encontrados {len(filtered_results)} documentos relevantes")
        context_text = "\n\n---\n\n".join([f"[Documento {i+1}]:\n{doc.page_content}" for i, doc in enumerate(filtered_results)])

        # Construir el prompt
        prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
        prompt = prompt_template.format(context=context_text, question=query_text)

        # Generar respuesta con Ollama
        model = get_unified_llm()
        response = model.invoke(prompt)

        print(f"\nüìÑ Respuesta: {response.strip()}\n")
        return response
        
    except Exception as e:
        print(f"‚ùå Error conectando a Qdrant: {e}")
        print("üí° Verifica tu QDRANT_URL y QDRANT_API_KEY")
        return "Error de conexi√≥n con la base de datos"